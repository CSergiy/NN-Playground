{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98030d3c",
   "metadata": {},
   "source": [
    "# NN Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef344",
   "metadata": {},
   "source": [
    "This notebook will be testing out variations on different neural networks, utilizing various forms of cells/nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951cbb3",
   "metadata": {},
   "source": [
    "Cell types include:\n",
    "-Backfed input Cell\n",
    "-Input Cell\n",
    "-Noisy Input Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f39bb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ae600",
   "metadata": {},
   "source": [
    "# Base NN Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7db57",
   "metadata": {},
   "source": [
    "Creating a BaseNN class intended to use inheritance in later implementations of different NN's when abstracting the base class to make specialized classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdcf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class for neural networks\n",
    "class BaseNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BaseNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"forward method must be implemented in derived classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a7800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural networks\n",
    "input_size = 2\n",
    "hidden_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab62054",
   "metadata": {},
   "source": [
    "# Basic Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f877d9a",
   "metadata": {},
   "source": [
    "## Perceptron (P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83688fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size):\n",
    "        # Initialize weights and bias randomly\n",
    "        self.weights = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "    def activate(self, x):\n",
    "        # Simple step function as activation\n",
    "        return 1 if x > 0 else 0\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "\n",
    "        # Apply the activation function\n",
    "        output = self.activate(weighted_sum)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f716aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.5 0.8]\n",
      "Output: 1\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a perceptron with 2 input cells\n",
    "    perceptron = Perceptron(input_size=2)\n",
    "\n",
    "    # Example input\n",
    "    input_data = np.array([0.5, 0.8])\n",
    "\n",
    "    # Get the output from the perceptron\n",
    "    output = perceptron.forward(input_data)\n",
    "\n",
    "    print(f\"Input: {input_data}\")\n",
    "    print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e298f2a",
   "metadata": {},
   "source": [
    "## Feed Forward (FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3c747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)  # Single output neuron\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the neural network\n",
    "input_size = 2  # Number of input features \n",
    "hidden_size = 3  # Number of neurons in the hidden layers\n",
    "model = FeedforwardNN(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09fa362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (hidden_layer): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.47794511914253235\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input\n",
    "sample_input = torch.tensor([[0.5, 0.3]])  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output = model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(model)\n",
    "print(\"Output:\", output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03243f0",
   "metadata": {},
   "source": [
    "# Radial Basis Network (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32822c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialBasisFunction:\n",
    "    def __init__(self, input_size, num_centers):\n",
    "        # Initialize centers and width parameters randomly\n",
    "        self.centers = np.random.rand(num_centers, input_size)\n",
    "        self.width = np.random.rand()\n",
    "        self.weights = np.random.rand(num_centers)\n",
    "    \n",
    "    def gaussian(self, x, center, width):\n",
    "        # Gaussian activation function\n",
    "        return np.exp(-np.sum((x - center)**2) / (2 * width**2))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Calculate the activation for each center\n",
    "        activations = np.array([self.gaussian(inputs, center, self.width) for center in self.centers])\n",
    "        \n",
    "        # Calculate the weighted sum of activations\n",
    "        weighted_sum = np.dot(activations, self.weights)\n",
    "        \n",
    "        # Apply a threshold for binary output\n",
    "        output = 1 if weighted_sum > 0.5 else 0\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ad0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.5 0.8]\n",
      "Output: 1\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an RBF network with 2 input cells and 3 centers\n",
    "    rbf_network = RadialBasisFunction(input_size=2, num_centers=3)\n",
    "    \n",
    "    # Example input\n",
    "    input_data = np.array([0.5, 0.8])\n",
    "    \n",
    "    # Get the output from the RBF network\n",
    "    output = rbf_network.forward(input_data)\n",
    "    \n",
    "    print(f\"Input: {input_data}\")\n",
    "    print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f57745",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__(input_size, hidden_size, output_size=1)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.recurrent_layer = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        h_t, _ = self.recurrent_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[:, -1, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b1b98",
   "metadata": {},
   "source": [
    "## Comparing FF & RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bc4603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward Model:\n",
      "FeedforwardNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (hidden_layer): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.729799747467041\n",
      "\n",
      "Simple RNN Model:\n",
      "SimpleRNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (recurrent_layer): RNN(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.7493574023246765\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models\n",
    "feedforward_model = FeedforwardNN(input_size, hidden_size)\n",
    "simple_rnn_model = SimpleRNN(input_size, hidden_size)\n",
    "\n",
    "# Forward pass for the feedforward model\n",
    "sample_input = torch.tensor([[0.5, 0.3]])\n",
    "output_feedforward = feedforward_model(sample_input)\n",
    "\n",
    "# Forward pass for the simple RNN model\n",
    "sample_input_rnn = torch.rand((1, 4, input_size))\n",
    "output_rnn = simple_rnn_model(sample_input_rnn)\n",
    "\n",
    "# Print the model architectures and outputs\n",
    "print(\"Feedforward Model:\")\n",
    "print(feedforward_model)\n",
    "print(\"Output:\", output_feedforward.item())\n",
    "\n",
    "print(\"\\nSimple RNN Model:\")\n",
    "print(simple_rnn_model)\n",
    "print(\"Output:\", output_rnn.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3ee08",
   "metadata": {},
   "source": [
    "# Deep Feed Forward (DFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d096c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Feed Forward Neural Network\n",
    "class DeepFeedforwardNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DeepFeedforwardNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_size, hidden_size) for _ in range(2)  # Two hidden layers with 4 nodes each\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e01181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFeedforwardNN(\n",
      "  (input_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=4, out_features=4, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "Output: tensor([[0.5660, 0.3460]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the deep feedforward neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 4  # Number of nodes in each hidden layer\n",
    "output_size = 2  # Number of output nodes\n",
    "deep_feedforward_model = DeepFeedforwardNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.tensor([[0.5, 0.3, 0.8]])  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_deep_feedforward = deep_feedforward_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(deep_feedforward_model)\n",
    "print(\"Output:\", output_deep_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e99e4",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16386575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Neural Network\n",
    "class LSTMNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.lstm_layer = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_t, c_t) = self.lstm_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[-1, :, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0792094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNN(\n",
      "  (lstm_layer): LSTM(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.3917, 0.5766, 0.5157, 0.4375]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LSTM neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 3  # Number of memory cells\n",
    "output_size = 4  # Number of output nodes\n",
    "lstm_model = LSTMNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, 4, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_lstm = lstm_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(lstm_model)\n",
    "print(\"Output:\", output_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0a067",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a021e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(GRUNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.gru_layer = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t, _ = self.gru_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[:, -1, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9345c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNN(\n",
      "  (gru_layer): GRU(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4354, 0.5022, 0.5707, 0.5334]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GRU neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 3  # Number of memory cells\n",
    "output_size = 4  # Number of output nodes\n",
    "gru_model = GRUNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, 4, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_gru = gru_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(gru_model)\n",
    "print(\"Output:\", output_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5104bd",
   "metadata": {},
   "source": [
    "# Auto Encoder (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93670d",
   "metadata": {},
   "source": [
    "AE designed for unsupervised learning & Data compression.\n",
    "\n",
    "Learns compact representation of input data.\n",
    "\n",
    "Used for data denoising, dimensionality reduction, feature learning.\n",
    "\n",
    "Versitile building block in utilizing NN's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe5d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = torch.relu(self.encoder(x))\n",
    "        decoded = torch.sigmoid(self.decoder(encoded))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f1bafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (decoder): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4270, 0.5819, 0.6050, 0.5539, 0.4236, 0.5984, 0.6222, 0.5810, 0.5461,\n",
      "         0.4906]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the autoencoder\n",
    "input_size = 10  # Number of input features\n",
    "hidden_size = 5  # Number of hidden nodes (compressed representation)\n",
    "autoencoder = Autoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))\n",
    "\n",
    "# Forward pass to get the reconstructed output\n",
    "output_autoencoder = autoencoder(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(autoencoder)\n",
    "print(\"Output:\", output_autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775f45f",
   "metadata": {},
   "source": [
    "# Variational AE (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2771e",
   "metadata": {},
   "source": [
    "VAE adds probabilistic approach to encoding. Generates deterministic encoding & probabilistic distribution over possible encodings. \n",
    "\n",
    "This enables model to generate new data points by sampling from the learned distribution.\n",
    "\n",
    "VAE good tool for data generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ed9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.encoder_fc2_mean = nn.Linear(hidden_size, hidden_size)\n",
    "        self.encoder_fc2_logvar = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_fc1 = nn.Linear(hidden_size, input_size)\n",
    "        self.decoder_fc2 = nn.Linear(input_size, input_size)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = torch.relu(self.encoder_fc1(x))\n",
    "        mean = self.encoder_fc2_mean(x)\n",
    "        logvar = self.encoder_fc2_logvar(x)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "\n",
    "        # Decoder\n",
    "        x_hat = torch.relu(self.decoder_fc1(z))\n",
    "        x_hat = torch.sigmoid(self.decoder_fc2(x_hat))\n",
    "\n",
    "        return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa8a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (encoder_fc2_mean): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (encoder_fc2_logvar): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (decoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (decoder_fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4220, 0.4546, 0.5274, 0.3855]], grad_fn=<SigmoidBackward0>)\n",
      "Mean: tensor([[ 0.1978, -0.5265, -0.4358,  0.5759]], grad_fn=<AddmmBackward0>)\n",
      "Log Variance: tensor([[0.7016, 0.8123, 0.0279, 0.1598]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the variational autoencoder\n",
    "input_size = 4  # Number of input features\n",
    "hidden_size = 4  # Number of hidden nodes in probabilistic layer\n",
    "vae = VariationalAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))\n",
    "\n",
    "# Forward pass to get the reconstructed output and latent variables\n",
    "output_vae, mean, logvar = vae(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(vae)\n",
    "print(\"Output:\", output_vae)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Log Variance:\", logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf95b0",
   "metadata": {},
   "source": [
    "# Denoising Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92eb90",
   "metadata": {},
   "source": [
    "DAE corrupts input data w/ noise. Therefore DAEs are forced to learn most robust & meaningful features.\n",
    "Results in resiliance against noisy inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0befd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_fc1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_fc1 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = torch.relu(self.encoder_fc1(x))\n",
    "\n",
    "        # Decoder\n",
    "        x_hat = torch.sigmoid(self.decoder_fc1(x))\n",
    "\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec37cfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenoisingAutoencoder(\n",
      "  (encoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (decoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "Noisy Input: tensor([[0.0886, 0.3265, 0.2430, 0.4412]])\n",
      "Reconstructed Output: tensor([[0.4467, 0.4789, 0.6245, 0.4430]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the denoising autoencoder\n",
    "input_size = 4  # Number of input features\n",
    "hidden_size = 4  # Number of hidden nodes\n",
    "dae = DenoisingAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input (noisy data)\n",
    "noisy_input = torch.rand((1, input_size))  # Example Noisy Data\n",
    "\n",
    "# Forward pass to get the reconstructed output\n",
    "output_dae = dae(noisy_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(dae)\n",
    "print(\"Noisy Input:\", noisy_input)\n",
    "print(\"Reconstructed Output:\", output_dae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1302da45",
   "metadata": {},
   "source": [
    "# Sparse Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273f9a",
   "metadata": {},
   "source": [
    "SAE involves additional constraint in the training process to encourage network to learn sparse representations w/ goal of learn more robust & efficent representations by promoting small number of neurons to be activate at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e588e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, sparsity_target=0.1, sparsity_weight=0.2):\n",
    "        super(SparseAutoencoder, self).__init__(input_size, hidden_size, output_size=input_size)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_fc1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_fc1 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        # Sparsity parameters\n",
    "        self.sparsity_target = sparsity_target\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        encoded = self.encoder_fc1(x)\n",
    "        encoded = self.relu(encoded)\n",
    "\n",
    "        # Decoder\n",
    "        decoded = torch.sigmoid(self.decoder_fc1(encoded))\n",
    "\n",
    "        return decoded, encoded\n",
    "\n",
    "    def loss_function(self, x, x_hat, encoded):\n",
    "        # Reconstruction loss\n",
    "        reconstruction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='mean')\n",
    "\n",
    "        # Sparsity loss\n",
    "        sparsity_loss = torch.sum(self.kl_divergence(self.sparsity_target, encoded))\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = reconstruction_loss + self.sparsity_weight * sparsity_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def kl_divergence(self, target, activations):\n",
    "        # KL Divergence to enforce sparsity\n",
    "        p = torch.mean(activations, dim=0)  # Average activation over the dataset\n",
    "        return target * torch.log(target / p) + (1 - target) * torch.log((1 - target) / (1 - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3951074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder(\n",
      "  (encoder_fc1): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (decoder_fc1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Input: tensor([[0.6333, 0.5426, 0.7588, 0.3070, 0.5324]])\n",
      "Reconstructed Output: tensor([[0.5462, 0.4714, 0.5358, 0.5153, 0.4913]], grad_fn=<SigmoidBackward0>)\n",
      "Encoded Representation: tensor([[0.8522, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "Loss: inf\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the sparse autoencoder\n",
    "input_size = 5  # Number of input features\n",
    "hidden_size = 3  # Number of hidden nodes\n",
    "sae = SparseAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the reconstructed output and encoded representation\n",
    "output_sae, encoded_sae = sae(sample_input)\n",
    "\n",
    "# Calculate the loss\n",
    "loss_sae = sae.loss_function(sample_input, output_sae, encoded_sae)\n",
    "\n",
    "# Print the model architecture, output, and loss\n",
    "print(sae)\n",
    "print(\"Input:\", sample_input)\n",
    "print(\"Reconstructed Output:\", output_sae)\n",
    "print(\"Encoded Representation:\", encoded_sae)\n",
    "print(\"Loss:\", loss_sae.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b869e1",
   "metadata": {},
   "source": [
    "# Markov Chain (MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89af0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChainNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MarkovChainNN, self).__init__(input_size, hidden_size, output_size=input_size)\n",
    "        self.transition_matrix = nn.Parameter(torch.randn(input_size, hidden_size))\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply a simple linear transformation based on the transition matrix\n",
    "        x = torch.matmul(x, self.transition_matrix)\n",
    "        # Apply a linear layer to get the final output\n",
    "        output = self.output_layer(x)\n",
    "        # You might want to apply some non-linearity here based on your specific needs\n",
    "        # For example, you can use torch.relu(output) or torch.sigmoid(output) depending on the task\n",
    "        return output\n",
    "\n",
    "# Instantiate the Markov Chain neural network\n",
    "input_size = 4  # Number of input features \n",
    "hidden_size = 8  # Number of hidden states\n",
    "markov_chain_model = MarkovChainNN(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_markov_chain = markov_chain_model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbcf5cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkovChainNN(\n",
      "  (output_layer): Linear(in_features=8, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[ 0.0210, -0.0391, -0.7962, -0.0839]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture and output\n",
    "print(markov_chain_model)\n",
    "print(\"Output:\", output_markov_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed412a",
   "metadata": {},
   "source": [
    "# Hopfield Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7c8d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HopfieldNetwork(BaseNN):\n",
    "    def __init__(self, input_size):\n",
    "        super(HopfieldNetwork, self).__init__(input_size, hidden_size=None, output_size=input_size)\n",
    "        \n",
    "        # Weight matrix for the Hopfield Network\n",
    "        self.weights = nn.Parameter(torch.zeros((input_size, input_size), dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the Hopfield Network dynamics\n",
    "        y = torch.sign(x @ self.weights).long()  # Convert to torch.long after applying sign\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "221dcea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HopfieldNetwork()\n",
      "Output: [[0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 5  # Change this based on your needs\n",
    "hopfield_model = HopfieldNetwork(input_size)\n",
    "\n",
    "# Define a sample input pattern (1 or -1)\n",
    "sample_input = torch.tensor([[1, -1, 1, -1, 1]], dtype=torch.float)  # Change the data type to torch.float\n",
    "\n",
    "# Forward pass to retrieve the output\n",
    "output_hopfield = hopfield_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(hopfield_model)\n",
    "print(\"Output:\", output_hopfield.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f9cec",
   "metadata": {},
   "source": [
    "# Boltzmann Machine (BM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d81af",
   "metadata": {},
   "source": [
    "BM is a stochastic RNN designed to find a probability distribution over its set of binary-valued patterns. \n",
    "\n",
    "*Main Objective* is to learn the joint probablity distribution of its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8f37f",
   "metadata": {},
   "source": [
    "Unique Features:\n",
    "-visible & hidden units forming bipartite graph\n",
    "-connects between units have weights & model learns weights during training\n",
    "-stochastic update process for both training & inference\n",
    "\n",
    "Common Uses:\n",
    "-unsupervised learning tasks like feature learning, dimensionality reduction, density estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7668407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoltzmannMachine(nn.Module):\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        super(BoltzmannMachine, self).__init__()\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "        # Define the parameters (weights and biases)\n",
    "        self.weights = nn.Parameter(torch.randn(num_visible, num_hidden))\n",
    "        self.visible_bias = nn.Parameter(torch.randn(num_visible))\n",
    "        self.hidden_bias = nn.Parameter(torch.randn(num_hidden))\n",
    "\n",
    "    def forward(self, visible_states):\n",
    "        # Ensure visible_states has the correct dimensions (batch_size x num_visible)\n",
    "        if visible_states.dim() == 1:\n",
    "            visible_states = visible_states.view(1, -1)\n",
    "\n",
    "        # Compute the hidden probabilities given visible states\n",
    "        hidden_probabilities = F.sigmoid(F.linear(visible_states, self.weights.t(), self.hidden_bias))\n",
    "\n",
    "        # Sample hidden states from the computed probabilities\n",
    "        hidden_states = torch.bernoulli(hidden_probabilities)\n",
    "\n",
    "        # Compute the visible probabilities given the sampled hidden states\n",
    "        visible_probabilities = F.sigmoid(F.linear(hidden_states, self.weights, self.visible_bias))\n",
    "\n",
    "        # Sample visible states from the computed probabilities\n",
    "        visible_states = torch.bernoulli(visible_probabilities)\n",
    "\n",
    "        return visible_states, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ebd1d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoltzmannMachine()\n",
      "Sampled Visible State: [[0. 0. 1. 1. 1.]]\n",
      "Sampled Hidden State: [[0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_visible = 5\n",
    "num_hidden = 3\n",
    "\n",
    "boltzmann_machine = BoltzmannMachine(num_visible, num_hidden)\n",
    "\n",
    "# Define a sample visible state (binary values)\n",
    "sample_visible_state = torch.tensor([1, 0, 1, 0, 1.], dtype=torch.float)\n",
    "\n",
    "# Perform a Gibbs sampling step\n",
    "sampled_visible, sampled_hidden = boltzmann_machine(sample_visible_state)\n",
    "\n",
    "# Print the model architecture and sampled states\n",
    "print(boltzmann_machine)\n",
    "print(\"Sampled Visible State:\", sampled_visible.detach().numpy())\n",
    "print(\"Sampled Hidden State:\", sampled_hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba54b75",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine (RBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ab0c6",
   "metadata": {},
   "source": [
    "Differences from normal Boltzmann Machine:\n",
    "\n",
    "    -No connections between units within same layer (no hidden-hidden or visible-visible connections)\n",
    "    \n",
    "    -Bipartite graph with one layer of visible units and one layer of hidden units\n",
    "    \n",
    "Objective: \n",
    "\n",
    "    -RBM objective with changes for potentially more effective feature learning\n",
    "\n",
    "Unique Features:\n",
    "\n",
    "    -Widely used for feature learning & are building blocks in deep learning architectures.\n",
    "    \n",
    "    -Efficent training, Contrastive Divergence (CD) is often used for training RBMs\n",
    "Common Uses:\n",
    "\n",
    "    -Feature Learning; pre-training deep NN\n",
    "    \n",
    "    -Collaborative filtering, topic modeling, other unsupervised learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27c65354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(BaseNN):\n",
    "    def __init__(self, visible_size, hidden_size):\n",
    "        super(RBM, self).__init__(visible_size, hidden_size, None)\n",
    "        self.weights = nn.Parameter(torch.randn(visible_size, hidden_size))\n",
    "        self.visible_bias = nn.Parameter(torch.zeros(visible_size))\n",
    "        self.hidden_bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_prob = F.sigmoid(F.linear(x, self.weights.t(), self.hidden_bias))\n",
    "        hidden_state = torch.bernoulli(hidden_prob)\n",
    "        reconstructed_prob = F.sigmoid(F.linear(hidden_state, self.weights, self.visible_bias))\n",
    "        return hidden_state, reconstructed_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0741e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM()\n",
      "Sampled Visible State: [[1. 0. 1. 0. 1.]]\n",
      "Hidden States: [[0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "visible_size = 5\n",
    "hidden_size = 3\n",
    "\n",
    "# Create an RBM model\n",
    "rbm_model = RBM(visible_size, hidden_size)\n",
    "\n",
    "# Define a sample visible state (binary values)\n",
    "sample_visible_state = torch.tensor([[1, 0, 1, 0, 1.]], dtype=torch.float)\n",
    "\n",
    "# Forward pass to get the hidden states\n",
    "hidden_states, _ = rbm_model(sample_visible_state)\n",
    "\n",
    "# Print the model architecture and hidden states\n",
    "print(rbm_model)\n",
    "print(\"Sampled Visible State:\", sample_visible_state.detach().numpy())\n",
    "print(\"Hidden States:\", hidden_states.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee6f13",
   "metadata": {},
   "source": [
    "# Deep Belief Network (DBN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930ddac",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "    -Unsupervised learning & feature learning\n",
    "    -Model complex hierarchical representations of data\n",
    "Unique Features:\n",
    "    \n",
    "    -Multiple layer of stochastic, latent variables (usually binary)\n",
    "    -Stack of Restricted Boltzmann Machines (See super in the DBN class init for implementing via making DBN layers)\n",
    "    - Uses a layer-wise pre-training approach followed by fine-tuning using backprop\n",
    "    \n",
    "Common Uses:\n",
    "    \n",
    "    - Feature Learning\n",
    "    - Generative tasks (new samples from learned distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a12d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN(BaseNN):\n",
    "    def __init__(self, visible_size, hidden_sizes):\n",
    "        super(DBN, self).__init__(visible_size, None, None)\n",
    "        self.rbm_layers = nn.ModuleList([RBM(visible_size, hidden_size) for hidden_size in hidden_sizes])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through each RBM layer\n",
    "        for rbm_layer in self.rbm_layers:\n",
    "            x, _ = rbm_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cd7ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBN(\n",
      "  (rbm_layers): ModuleList(\n",
      "    (0-1): 2 x RBM()\n",
      "  )\n",
      ")\n",
      "Output: [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "visible_size = 5\n",
    "hidden_sizes = [5, 1]\n",
    "\n",
    "# Create a Deep Belief Network\n",
    "dbn_model = DBN(visible_size, hidden_sizes)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, visible_size))\n",
    "\n",
    "# Forward pass through the DBN\n",
    "output_dbn = dbn_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(dbn_model)\n",
    "print(\"Output:\", output_dbn.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf783d",
   "metadata": {},
   "source": [
    "# Deep Convolutional Network (DCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878295fe",
   "metadata": {},
   "source": [
    "Objective:\n",
    "    \n",
    "    -Processing structured grid data like images\n",
    "    -Excels @ capturing hierarchical spatial patterns\n",
    "\n",
    "Unique Features:\n",
    "    \n",
    "    -Uses convolutional layers w/ learnable filters that capture local patterns\n",
    "    -Typically includes pooling layers to reduce spatial dimensions & increase computational efficency\n",
    "    -Uses shared weights in convolutional layers for translation invariance\n",
    "    \n",
    "Common uses:\n",
    "    \n",
    "    -Image classification\n",
    "    -Feature learning in spatial data (hierarchical representations of spatial features)\n",
    "    -Transfer learning (pre-trained CNNs on large datasets often fine-tuned for specific tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "298e0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(BaseNN):\n",
    "    def __init__(self, input_channels, num_classes, image_size):\n",
    "        hidden_size = 64\n",
    "\n",
    "        super(DeepCNN, self).__init__(input_size=image_size, hidden_size=hidden_size, output_size=num_classes)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df257385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Output Scores: [[ 0.12570626  0.10115343  0.03376044  0.06880514 -0.01437923 -0.09773049\n",
      "  -0.01460256  0.09239314  0.05630538 -0.08280865]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_channels = 1  # Grayscale images\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "\n",
    "deep_cnn_model = DeepCNN(input_channels, num_classes, image_size)\n",
    "\n",
    "sample_image = torch.rand((1, input_channels, image_size, image_size))\n",
    "\n",
    "output_scores = deep_cnn_model(sample_image)\n",
    "\n",
    "print(deep_cnn_model)\n",
    "print(\"Output Scores:\", output_scores.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a12407",
   "metadata": {},
   "source": [
    "# Deconvolutional Network (DN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63514c4",
   "metadata": {},
   "source": [
    "Objective:\n",
    "    \n",
    "    -Reconstruction & generation of struuctured data (especially images)\n",
    "    -specialize in capturing hierarchical spatial patterns\n",
    "\n",
    "Unique Features:\n",
    "    \n",
    "    -deconvolutional layers w/ learnable filters for reconstructing spatial patterns\n",
    "    -usually include unpooling layers to increase spatial dimensions while maintaining computational efficency\n",
    "    -shared weights in deconvolutional layers to introduce translation invariance during reconstruction\n",
    "    \n",
    "Common uses:\n",
    "    \n",
    "    -image reconstruction & generation\n",
    "    -feature learning in spatial data w/ focus on capturing hierarchical spatial patterns\n",
    "    -semantic segmentation in images\n",
    "    -inverse problems (ex.image restoration)\n",
    "    -transfer learning (pre-trained on larger dataset -> fine-tuned for specicific reconstruction task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "517b9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDeconvNet(BaseNN):\n",
    "    def __init__(self, input_channels, output_channels, output_size):\n",
    "        hidden_size = 64\n",
    "\n",
    "        super(DeepDeconvNet, self).__init__(input_size=None, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 64 * (output_size // 4) * (output_size // 4))\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=32, out_channels=output_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.view(-1, 64, (self.output_size // 4), (self.output_size // 4))\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.sigmoid(self.deconv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289d189",
   "metadata": {},
   "source": [
    "notes on parameters above: \n",
    "\n",
    "    channels: in context of images, 1=grayscale, 3=RGB\n",
    "    kernel_size: size of convolutional kernel-filter, size of local region considered for each convolutional operation\n",
    "    stride: step-size\n",
    "    padding: zero-padding addied to input of each side, helps maintain/adjust spatial dimensions\n",
    "    output_size: shape of output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbb68582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepDeconvNet(\n",
      "  (fc1): Linear(in_features=64, out_features=3136, bias=True)\n",
      "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (deconv2): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      ")\n",
      "Output Image Shape: torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_channels = 1  # Grayscale images\n",
    "output_channels = 3  # Number of channels in the output image (e.g., RGB)\n",
    "output_size = 28\n",
    "\n",
    "deep_deconv_model = DeepDeconvNet(input_channels, output_channels, output_size)\n",
    "\n",
    "sample_latent_vector = torch.rand((1, deep_deconv_model.hidden_size))\n",
    "\n",
    "output_image = deep_deconv_model(sample_latent_vector)\n",
    "\n",
    "print(deep_deconv_model)\n",
    "print(\"Output Image Shape:\", output_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282738d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
