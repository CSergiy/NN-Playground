{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98030d3c",
   "metadata": {},
   "source": [
    "# NN Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef344",
   "metadata": {},
   "source": [
    "This notebook will be testing out variations on different neural networks, utilizing various forms of cells/nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951cbb3",
   "metadata": {},
   "source": [
    "Cell types include:\n",
    "-Backfed input Cell\n",
    "-Input Cell\n",
    "-Noisy Input Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f39bb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ae600",
   "metadata": {},
   "source": [
    "# Base NN Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7db57",
   "metadata": {},
   "source": [
    "Creating a BaseNN class intended to use inheritance in later implementations of different NN's when abstracting the base class to make specialized classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdcf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class for neural networks\n",
    "class BaseNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BaseNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"forward method must be implemented in derived classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a7800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural networks\n",
    "input_size = 2\n",
    "hidden_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab62054",
   "metadata": {},
   "source": [
    "# Basic Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f877d9a",
   "metadata": {},
   "source": [
    "## Perceptron (P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83688fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size):\n",
    "        # Initialize weights and bias randomly\n",
    "        self.weights = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "    def activate(self, x):\n",
    "        # Simple step function as activation\n",
    "        return 1 if x > 0 else 0\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "\n",
    "        # Apply the activation function\n",
    "        output = self.activate(weighted_sum)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f716aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.5 0.8]\n",
      "Output: 1\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a perceptron with 2 input cells\n",
    "    perceptron = Perceptron(input_size=2)\n",
    "\n",
    "    # Example input\n",
    "    input_data = np.array([0.5, 0.8])\n",
    "\n",
    "    # Get the output from the perceptron\n",
    "    output = perceptron.forward(input_data)\n",
    "\n",
    "    print(f\"Input: {input_data}\")\n",
    "    print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e298f2a",
   "metadata": {},
   "source": [
    "## Feed Forward (FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3c747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)  # Single output neuron\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the neural network\n",
    "input_size = 2  # Number of input features \n",
    "hidden_size = 3  # Number of neurons in the hidden layers\n",
    "model = FeedforwardNN(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09fa362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (hidden_layer): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.4823249578475952\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input\n",
    "sample_input = torch.tensor([[0.5, 0.3]])  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output = model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(model)\n",
    "print(\"Output:\", output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03243f0",
   "metadata": {},
   "source": [
    "# Radial Basis Network (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32822c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialBasisFunction:\n",
    "    def __init__(self, input_size, num_centers):\n",
    "        # Initialize centers and width parameters randomly\n",
    "        self.centers = np.random.rand(num_centers, input_size)\n",
    "        self.width = np.random.rand()\n",
    "        self.weights = np.random.rand(num_centers)\n",
    "    \n",
    "    def gaussian(self, x, center, width):\n",
    "        # Gaussian activation function\n",
    "        return np.exp(-np.sum((x - center)**2) / (2 * width**2))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Calculate the activation for each center\n",
    "        activations = np.array([self.gaussian(inputs, center, self.width) for center in self.centers])\n",
    "        \n",
    "        # Calculate the weighted sum of activations\n",
    "        weighted_sum = np.dot(activations, self.weights)\n",
    "        \n",
    "        # Apply a threshold for binary output\n",
    "        output = 1 if weighted_sum > 0.5 else 0\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ad0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.5 0.8]\n",
      "Output: 0\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an RBF network with 2 input cells and 3 centers\n",
    "    rbf_network = RadialBasisFunction(input_size=2, num_centers=3)\n",
    "    \n",
    "    # Example input\n",
    "    input_data = np.array([0.5, 0.8])\n",
    "    \n",
    "    # Get the output from the RBF network\n",
    "    output = rbf_network.forward(input_data)\n",
    "    \n",
    "    print(f\"Input: {input_data}\")\n",
    "    print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f57745",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__(input_size, hidden_size, output_size=1)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.recurrent_layer = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        h_t, _ = self.recurrent_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[:, -1, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b1b98",
   "metadata": {},
   "source": [
    "## Comparing FF & RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bc4603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward Model:\n",
      "FeedforwardNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (hidden_layer): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.5554649829864502\n",
      "\n",
      "Simple RNN Model:\n",
      "SimpleRNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (recurrent_layer): RNN(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Output: 0.36250656843185425\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models\n",
    "feedforward_model = FeedforwardNN(input_size, hidden_size)\n",
    "simple_rnn_model = SimpleRNN(input_size, hidden_size)\n",
    "\n",
    "# Forward pass for the feedforward model\n",
    "sample_input = torch.tensor([[0.5, 0.3]])\n",
    "output_feedforward = feedforward_model(sample_input)\n",
    "\n",
    "# Forward pass for the simple RNN model\n",
    "sample_input_rnn = torch.rand((1, 4, input_size))\n",
    "output_rnn = simple_rnn_model(sample_input_rnn)\n",
    "\n",
    "# Print the model architectures and outputs\n",
    "print(\"Feedforward Model:\")\n",
    "print(feedforward_model)\n",
    "print(\"Output:\", output_feedforward.item())\n",
    "\n",
    "print(\"\\nSimple RNN Model:\")\n",
    "print(simple_rnn_model)\n",
    "print(\"Output:\", output_rnn.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3ee08",
   "metadata": {},
   "source": [
    "# Deep Feed Forward (DFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d096c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Feed Forward Neural Network\n",
    "class DeepFeedforwardNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DeepFeedforwardNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_size, hidden_size) for _ in range(2)  # Two hidden layers with 4 nodes each\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e01181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFeedforwardNN(\n",
      "  (input_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=4, out_features=4, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4105, 0.5895]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the deep feedforward neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 4  # Number of nodes in each hidden layer\n",
    "output_size = 2  # Number of output nodes\n",
    "deep_feedforward_model = DeepFeedforwardNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.tensor([[0.5, 0.3, 0.8]])  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_deep_feedforward = deep_feedforward_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(deep_feedforward_model)\n",
    "print(\"Output:\", output_deep_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e99e4",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16386575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Neural Network\n",
    "class LSTMNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.lstm_layer = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_t, c_t) = self.lstm_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[-1, :, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0792094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNN(\n",
      "  (lstm_layer): LSTM(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4899, 0.5009, 0.4056, 0.5740]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LSTM neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 3  # Number of memory cells\n",
    "output_size = 4  # Number of output nodes\n",
    "lstm_model = LSTMNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, 4, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_lstm = lstm_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(lstm_model)\n",
    "print(\"Output:\", output_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0a067",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a021e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNN(BaseNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(GRUNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.gru_layer = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t, _ = self.gru_layer(x)\n",
    "        output = torch.sigmoid(self.output_layer(h_t[:, -1, :]))  # Taking the output from the last time step\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9345c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNN(\n",
      "  (gru_layer): GRU(3, 3, batch_first=True)\n",
      "  (output_layer): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.2902, 0.5306, 0.5113, 0.4946]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GRU neural network\n",
    "input_size = 3  # Number of input features \n",
    "hidden_size = 3  # Number of memory cells\n",
    "output_size = 4  # Number of output nodes\n",
    "gru_model = GRUNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, 4, input_size))  # Example Data\n",
    "\n",
    "# Forward pass to get the output\n",
    "output_gru = gru_model(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(gru_model)\n",
    "print(\"Output:\", output_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5104bd",
   "metadata": {},
   "source": [
    "# Auto Encoder (AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe5d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = torch.relu(self.encoder(x))\n",
    "        decoded = torch.sigmoid(self.decoder(encoded))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f1bafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (decoder): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4823, 0.4569, 0.4306, 0.4428, 0.5675, 0.3550, 0.4281, 0.5221, 0.4918,\n",
      "         0.4470]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the autoencoder\n",
    "input_size = 10  # Number of input features\n",
    "hidden_size = 5  # Number of hidden nodes (compressed representation)\n",
    "autoencoder = Autoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))\n",
    "\n",
    "# Forward pass to get the reconstructed output\n",
    "output_autoencoder = autoencoder(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(autoencoder)\n",
    "print(\"Output:\", output_autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775f45f",
   "metadata": {},
   "source": [
    "# Variational AE (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ed9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.encoder_fc2_mean = nn.Linear(hidden_size, hidden_size)\n",
    "        self.encoder_fc2_logvar = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_fc1 = nn.Linear(hidden_size, input_size)\n",
    "        self.decoder_fc2 = nn.Linear(input_size, input_size)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = torch.relu(self.encoder_fc1(x))\n",
    "        mean = self.encoder_fc2_mean(x)\n",
    "        logvar = self.encoder_fc2_logvar(x)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "\n",
    "        # Decoder\n",
    "        x_hat = torch.relu(self.decoder_fc1(z))\n",
    "        x_hat = torch.sigmoid(self.decoder_fc2(x_hat))\n",
    "\n",
    "        return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa8a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (encoder_fc2_mean): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (encoder_fc2_logvar): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (decoder_fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (decoder_fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4330, 0.5338, 0.3577, 0.3295]], grad_fn=<SigmoidBackward0>)\n",
      "Mean: tensor([[-0.3101, -0.2446,  0.1739, -0.5934]], grad_fn=<AddmmBackward0>)\n",
      "Log Variance: tensor([[-0.1155,  0.2399, -0.5895, -0.4484]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the variational autoencoder\n",
    "input_size = 4  # Number of input features\n",
    "hidden_size = 4  # Number of hidden nodes in probabilistic layer\n",
    "vae = VariationalAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define a sample input\n",
    "sample_input = torch.rand((1, input_size))\n",
    "\n",
    "# Forward pass to get the reconstructed output and latent variables\n",
    "output_vae, mean, logvar = vae(sample_input)\n",
    "\n",
    "# Print the model architecture and output\n",
    "print(vae)\n",
    "print(\"Output:\", output_vae)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Log Variance:\", logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46405b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
