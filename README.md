# Neural Network Playground

## Table of Contents
- [About](#about)
- [Nodes and Architectures](#nodes-and-architectures)
- [Implemented Networks](#implemented-networks)
- [Future Networks to Implement](#future-networks-to-implement)
- [Prerequisites](#prerequisites)
- [Results](#results)
- [Future Steps](#future-steps)

## About
This repository is dedicated to exploring and testing the implementation of various neural network architectures for personal educational purposes. 

## Nodes and Architectures
- Backfed Input Cell
- Input Cell
- Noisy Input Cell
- Hidden Cell
- Probabilistic Hidden Cell
- Spiking Hidden Cell
- Output Cell
- Matching Input Output Cell
- Recurrent Cell
- Memory Cell
- Different Memory Cell
- Keynel
- Convolution
- Pool

## Implemented Networks
- Perceptron (P)
- Feed Forward (FF)
- Radial Basis Network (RBF)
- Recurrent Neural NEtwork (RNN)
- Deep Feed Forward (DFF)
- Long Short Term Memory (LSTM)
- Gated Recurrent Unit (GRU)
- Auto Encoder (AE)
- Variational Auto Encoder (VAE)
- Denoising Auto Encoder (DAE)
- Sparse Auto Encoder (SAE)

## Future Networks to Implement
- MC
- HN
- BM
- RBM
- DBN
- DCN
- DN
- DCIGN
- GAN
- LSM
- ELM
- ESN
- DRN
- KN
- SVM
- NTM

## Prerequisites
To run this project, make sure you have the following packages installed:

```sh
pip install numpy torch
```

## Results
This project aims to explore and implement various neural network architectures for educational purposes. As of now, the project is in its early stages, and results will be updated and added to the respective sections as the implementation progresses.

## Future Steps
The following are the planned future steps for this project:
- Finish adding different forms of NN to test
- Further exploration of neural network architectures.
- Fine-tuning and optimization of implemented networks.
- Experimentation with additional datasets and scenarios.
