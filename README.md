# Neural Network Playground

## Table of Contents
- [About](#about)
- [Nodes and Architectures](#nodes-and-architectures)
- [Implemented Networks](#implemented-networks)
- [Future Networks to Implement](#future-networks-to-implement)
- [Prerequisites](#prerequisites)
- [Results](#results)
- [Future Steps](#future-steps)

## About
This repository is dedicated to exploring and testing the implementation of various neural network architectures for personal educational purposes. The project starts by following a chart that outlines different types of nodes, including backfed input cell, input cell, noisy input cell, hidden cell, probabilistic hidden cell, spiking hidden cell, output cell, matching input output cell, recurrent cell, memory cell, different memory cell, keynel, convolution, or pool.

## Nodes and Architectures
- Backfed Input Cell
- Input Cell
- Noisy Input Cell
- Hidden Cell
- Probabilistic Hidden Cell
- Spiking Hidden Cell
- Output Cell
- Matching Input Output Cell
- Recurrent Cell
- Memory Cell
- Different Memory Cell
- Keynel
- Convolution
- Pool

## Implemented Networks
- Perceptron (P)
- Feed Forward (FF)

## Future Networks to Implement
- RBF
- DFF
- RNN
- LSTM
- GRU
- AE
- VAE
- DAE
- SAE
- MC
- HN
- BM
- RBM
- DBN
- DCN
- DN
- DCIGN
- GAN
- LSM
- ELM
- ESN
- DRN
- KN
- SVM
- NTM

## Prerequisites
To run this project, make sure you have the following packages installed:

```sh
pip install [to be added in future]
```

## Results
This project aims to explore and implement various neural network architectures for educational purposes. As of now, the project is in its early stages, and results will be updated and added to the respective sections as the implementation progresses.

## Future Steps
The following are the planned future steps for this project:
- Finish adding different forms of NN to test
- Further exploration of neural network architectures.
- Fine-tuning and optimization of implemented networks.
- Experimentation with additional datasets and scenarios.
